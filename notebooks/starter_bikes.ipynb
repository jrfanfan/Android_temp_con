{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "starter_bank.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrfanfan/Android_temp_con/blob/main/notebooks/starter_bikes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StiU5QcPPxqQ"
      },
      "source": [
        "# Load Data\n",
        "import pandas as pd\n",
        "\n",
        "bikes = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bikes.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALLMN63FPyEQ"
      },
      "source": [
        "bikes.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnGBwGVZPyyh"
      },
      "source": [
        "# Convert bikes['dteday'] object to date\n",
        "bikes['dteday'] = pd.to_datetime(bikes['dteday'])\n",
        "bikes['yr'] = bikes['dteday'].dt.year\n",
        "bikes['mnth'] = bikes['dteday'].dt.month\n",
        "bikes['day'] = bikes['dteday'].dt.day\n",
        "bikes.info()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVSfaqgKPzE2"
      },
      "source": [
        "# Sum of bikes['casual'] and bikes['registered']\n",
        "bikes['rent_total'] = bikes['casual'] + bikes['registered']\n",
        "bikes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new dataframe called X that contians the features we're going\n",
        "# to use to make predictions\n",
        "X = bikes.drop(columns=['dteday', 'casual', 'registered', 'rent_total'])\n"
      ],
      "metadata": {
        "id": "l3YR78sTnX-p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new dataframe called y that contians the target we're\n",
        "# trying to predict\n",
        "y = bikes['rent_total']"
      ],
      "metadata": {
        "id": "WTUb5qYYp96d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import and use the train_test_split() function to split the X and y\n",
        "# dataframes into training and test sets.\n",
        "import sklearn.model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "-pYgqi5puZQc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# fit scaler on training data\n",
        "norm = MinMaxScaler().fit(X_train)\n",
        "\n",
        "# transform training data\n",
        "X_train = norm.transform(X_train)\n",
        "\n",
        "# transform testing dataabs\n",
        "X_test = norm.transform(X_test)"
      ],
      "metadata": {
        "id": "Yq-BdBZawl11"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the libraries we need\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import wrappers\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n"
      ],
      "metadata": {
        "id": "MaGAKcZy1ZwJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build a neural network using a sequential model\n",
        "# input layer node size is the same as the training columns\n",
        "# hidden layers: 128 node layer, 256 node layer, 64 node layer\n",
        "# a single node output layer\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=len(X_train[0]), activation='sigmoid'))\n",
        "model.add(Dropout(.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(64, activation='leaky_relu'))\n",
        "\n",
        "model.add(Dense(1, activation='relu'))"
      ],
      "metadata": {
        "id": "nkHQxD_c9itb",
        "outputId": "21d3ab8a-2fb4-45d3-9581-31b307291df7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    }
  ]
}